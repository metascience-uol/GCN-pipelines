{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "This script makes sure all pipelines in the data base will have similar boundary conditions:\n",
    "\n",
    "1. They have to start with \"Software\", so if this is missing we add it\n",
    "2. They have to end with \"Graph_measure\" followed by \"Result_aggregation\", we remove the aggregation step.\n",
    "3. After applying the firs two steps, only 10 out of 220 Pipelines have different ending points. For now we exclude them but we should further check these manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "wd = os.getcwd()\n",
    "pipeline_df = pd.read_excel(f'{wd}/data/Database.xlsx', sheet_name='Coding_steps')\n",
    "\n",
    "# Process the data to create the list of pipelines\n",
    "pipelines = pipeline_df.apply(lambda row: row.dropna().tolist(), axis=1).tolist()\n",
    "authors = [pipeline[0] for pipeline in pipelines]\n",
    "pipelines = [pipeline[1:] for pipeline in pipelines]\n",
    "\n",
    "# Ensure every pipeline starts with \"Software\" if it does not already\n",
    "modified_pipelines = [[\"Software\"] + pipeline if pipeline[0] != \"Software\" else pipeline for pipeline in pipelines]\n",
    "\n",
    "# Remove \"Result_aggregation\" if the step before is \"Graph_measures\"\n",
    "for pipeline in modified_pipelines:\n",
    "    if len(pipeline) > 1 and pipeline[-1] == \"Result_aggregation\" and pipeline[-2] == \"Graph_measures\":\n",
    "        pipeline.pop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the cleaned data for use in the main script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the matching pipelines and their corresponding authors\n",
    "matching_pipelines = [\n",
    "    pipeline for pipeline in modified_pipelines if pipeline[0] == \"Software\" and pipeline[-1] == \"Graph_measures\"\n",
    "]\n",
    "matching_authors = [\n",
    "    authors[i] for i, pipeline in enumerate(modified_pipelines) if pipeline[0] == \"Software\" and pipeline[-1] == \"Graph_measures\"\n",
    "]\n",
    "\n",
    "# Create a DataFrame with each pipeline step as a separate column\n",
    "max_steps = max(len(pipeline) for pipeline in matching_pipelines)\n",
    "matching_pipelines_df = pd.DataFrame([pipeline + [None]*(max_steps-len(pipeline)) for pipeline in matching_pipelines])\n",
    "matching_pipelines_df.insert(0, 'Author', matching_authors)\n",
    "\n",
    "matching_pipelines_df.to_excel(f'{wd}/Data/Database_clean.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stellar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
